import os
import torch
import numpy as np
import pandas as pd
import string
from torch import tensor
from torch.utils.data import Dataset


class ExeDataset(Dataset):
    def __init__(self, root_dir, csv_file, first_n_byte=1024):
        self.root_dir = root_dir
        self.fp_list = [files + '.bytes' for files in pd.read_csv(csv_file)['md5']]
        self.fp_id = [files for files in pd.read_csv(csv_file)['md5']]
        self.label_frame = pd.read_csv(csv_file)
        self.max_size = first_n_byte
        self.label = list(self.label_frame.iloc[:,1:].idxmax(axis=1))

    def __len__(self):
        return len(self.fp_list)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        with open(os.path.join(self.root_dir,self.fp_list[idx]), 'r') as f:
            head = [next(f) for x in range(int(self.max_size/16)+1)] # speed up rather than read whole .bytes files
            all_data = sum([byte_to_ascii(line) for line in head], [])
            # Padding to 1024 bytes
            diff_to_pad = self.max_size - len(all_data)
            all_data = all_data + [0] * diff_to_pad if diff_to_pad > 0 else all_data[:self.max_size]
            id = self.fp_list[idx][:-6]
            label_idx = self.label_frame['md5'] == self.fp_list[idx][:-6] # for '.bytes'
        seq_data, label = tensor(all_data), tensor(np.squeeze(self.label_frame[label_idx].iloc[:,1:].values))
        return seq_data, label, id

class ExeTestDataset(Dataset):
    def __init__(self, root_dir, csv_file, first_n_byte=1024):
        self.root_dir = root_dir
        self.fp_list = [files + '.bytes' for files in pd.read_csv(csv_file)['md5']]
        self.fp_id = [files for files in pd.read_csv(csv_file)['md5']]
        self.label_frame = pd.read_csv(csv_file)
        self.max_size = first_n_byte

    def __len__(self):
        return len(self.fp_list)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        with open(os.path.join(self.root_dir,self.fp_list[idx]), 'r') as f:
            head = [next(f) for x in range(int(self.max_size/16)+1)] # speed up rather than read whole .bytes files
            all_data = sum([byte_to_ascii(line) for line in head], [])
            # Padding to 1024 bytes
            diff_to_pad = self.max_size - len(all_data)
            all_data = all_data + [0] * diff_to_pad if diff_to_pad > 0 else all_data[:self.max_size]
            id =self.fp_list[idx][:-6]   # for '.bytes'
            label_idx = self.label_frame['md5'] == id
        seq_data, label = tensor(all_data), tensor(np.squeeze(self.label_frame[label_idx].iloc[:,1:].values))
        return seq_data, id

def byte_to_ascii(line):
    line = line.split()[1:]
    return [int(x, 16) + 1 for x in line]
