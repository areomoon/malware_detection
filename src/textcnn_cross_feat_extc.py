import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import argparse
from tqdm import tqdm
from model.Malware_Textcnn import MalTCNNnet_cv_feature
from utils.dataloader_seq import ExeDataset,ExeTestDataset
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torch.optim import Adam
from torch.optim import lr_scheduler

def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024 ** 2
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else:
                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024 ** 2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (
                start_mem - end_mem) / start_mem))
    return df

def to_np(t):
    return t.cpu().detach().numpy()

def str2bool(v):
    return v.lower() in ("yes", "true", "t", "1")

def save_model(dir_name, model, idx):
    print("MalCNNmodel_{}.model".format(idx))
    save_state_path = os.path.join(dir_name, 'MalCNNmodel_'+ idx +'_dict.pkl')
    torch.save(model.state_dict(), save_state_path)
    print("Chekcpoint saved")

def load_model(dict_name, model, idx):
    save_state_path = os.path.join(dict_name, 'MalCNNmodel_'+ idx +'_dict.pkl')
    state = torch.load(save_state_path)
    model.load_state_dict(state)
    print("Chekcpoint Loaded")

def valid_predict(model,valid_loader,device, id_list, img_feature_array_list):
    model.eval()
    with torch.no_grad():
        for batch_idx, (seq, tags, id) in enumerate(valid_loader):
            seq = seq.to(device)
            _, outputs = model(seq)

            id_list.append(id[0])
            img_feature_array_list.append(to_np(outputs)[0])

def test_predict(model,valid_loader,device, id_dict):
    model.eval()
    with torch.no_grad():
        for batch_idx, (seq, id) in enumerate(valid_loader):
            seq = seq.to(device)
            _, outputs = model(seq) # WIP

            if id in id_dict.keys():
                id_dict[id] += to_np(outputs)[0]
            else:
                id_dict.update({id[0]:to_np(outputs)[0]})


parser = argparse.ArgumentParser(description='TextCNN Malware Detection With Pytorch')

train_set = parser.add_mutually_exclusive_group()
parser.add_argument('--dataset', default='../train', type=str,
                    help='Dataset root directory path')
parser.add_argument('--label_file', default='../train/train.csv', type=str,
                    help='Specify Label Data path')
parser.add_argument('--use_model_weights', default=False, type=str2bool,
                    help='Use Pretrained model')
parser.add_argument('--pretrained_weights', default=None, type=str,
                    help='Pretrained model Idx')
parser.add_argument('--model_save_dir',default='model/tcnn_weights', type=str,
                    help='Trained Model State Dict Saved Path')
parser.add_argument('--epochs', default=8, type=int,
                    help='Number of epoch for training')
parser.add_argument('--batch_size', default=256, type=int,
                    help='Batch size for training')
parser.add_argument('--num_workers', default=0, type=int,
                    help='Number of workers used in dataloading')
parser.add_argument('--cuda', default=False, type=str2bool,
                    help='Use CUDA to train model')
parser.add_argument('--num_of_class', default=10, type=int,
                    help='Number of classes to predict')
parser.add_argument('--input_len', default=4096, type=int,
                    help='Length of Input for bytes file')
parser.add_argument('--window', default=32, type=int,
                    help='Window size of Dilated CNN')
parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,
                    help='initial learning rate')
parser.add_argument('--momentum', default=0.9, type=float,
                    help='Momentum value for optim')
parser.add_argument('--weight_decay', default=1e-4, type=float,
                    help='Weight decay for SGD')
parser.add_argument('--gamma', default=0.8, type=float,
                    help='Gamma update if use SGD as optimizer')
parser.add_argument('--log_interval', default=200, type=int,
                    help='Check model training for each k steps')
parser.add_argument('--mode', default='train',
                    help='Choose Train or Eval mode')
parser.add_argument('--do_eval', default=True, type=str2bool,
                    help='Whether to do evaluation on validation set')
parser.add_argument('--save_weights', default=False, type=str2bool,
                    help='Whether to do evaluation on validation set')
parser.add_argument('--cv', default=True, type=str2bool,
                    help='Whether to do evaluation on validation set')
# val logloss  1.2262,  w=16, input_len=2048  batch=256  epoch=10 best
# val logloss  1.2059,  w=32, input_len=4096  batch=256  epoch=10 best
# val logloss  1.2334,  w=16, input_len=4096  batch=256  epoch=13 best 0.9-0.1
# val logloss  1.2409,  w=8,  input_len=4096  batch=256  epoch=22 best 0.9-0.1

# 6, 7, 9 TrojanDownloader,VirTool, Worm

args = parser.parse_args()

if torch.cuda.is_available():
    if args.cuda:
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
    if not args.cuda:
        print("WARNING: It looks like you have a CUDA device, but aren't " +
              "using CUDA.\n Run with --cuda for optimal training speed.")
        torch.set_default_tensor_type('torch.FloatTensor')
else:
    torch.set_default_tensor_type('torch.FloatTensor')

# Load Neural Network Model
model = MalTCNNnet_cv_feature(num_of_classes= args.num_of_class,input_length=args.input_len ,window_size=args.window)

if torch.cuda.is_available() and torch.cuda.device_count() > 0:
    print("GPU device is available")
    device = torch.device('cuda')
    model.to(device)
else:
    device = torch.device('cpu')
    model.to(device)

# Define Loss function
loss_func = nn.CrossEntropyLoss()

if args.cuda:
    model= torch.nn.DataParallel(model)
    model.cuda()
    loss_func.cuda()

# Load pretrained weights
if args.use_model_weights:
    try:
        load_model(args.model_save_dir, model, args.pretrained_weights)
    except FileExistsError:
        print('Please specify the correct pretrained model weights path')

# Define Optimizer
optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
scheduler = lr_scheduler.StepLR(optimizer, 20, gamma=args.gamma)

print('Loading the dataset...')
print('Training Malware TextCNN net on: ', args.dataset)
print('Using the specified args:')
print(args)


if args.cv:
    import copy
    from sklearn.model_selection import StratifiedKFold

    train_data = ExeDataset(root_dir=args.dataset, csv_file=args.label_file, first_n_byte=args.input_len)
    eval_data = ExeTestDataset(root_dir='../test',csv_file='../ResultSample.csv', first_n_byte=args.input_len)
    eval_loader = DataLoader(eval_data, batch_size=1, num_workers=args.num_workers, shuffle=False)

    dataset_size = len(train_data)
    indices = list(range(dataset_size))
    indices_label = train_data.label
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    init_state = copy.deepcopy(model.state_dict())
    init_state_opt = copy.deepcopy(optimizer.state_dict())


    train_id_list = []
    train_img_feature_array_list = []

    test_id_dict = {}

    for i ,(train_indices, val_indices) in  enumerate(skf.split(indices, indices_label)):
        print('-'*30)
        print('{}-fold'.format(i+1))
        print('-'*30)
        model.load_state_dict(init_state)
        optimizer.load_state_dict(init_state_opt)

        train_sampler = SubsetRandomSampler(train_indices)
        valid_sampler = SubsetRandomSampler(val_indices)

        train_loader = DataLoader(train_data, batch_size=args.batch_size, num_workers=args.num_workers,
                                  sampler=train_sampler)
        valid_loader = DataLoader(train_data, batch_size=1, num_workers=args.num_workers,
                                  sampler=valid_sampler)

        for epoch_idx in tqdm(range(args.epochs)):
            print('Start Epoch {} / {}'.format(epoch_idx, args.epochs))
            train_loss = 0.0
            train_correct = 0.0
            n_sample = 0
            step=0
            model.train()

            for batch_idx, (seq, tags, _) in enumerate(train_loader):
                optimizer.zero_grad()
                seq = seq.to(device)
                tags = tags.to(device)
                outputs, _ = model(seq)
                loss = loss_func(outputs, torch.argmax(tags,dim=1))
                loss.backward()
                optimizer.step()

                predict_vector = np.argmax(to_np(outputs), axis=1)
                label_vector = np.argmax(to_np(tags), axis=1)
                bool_vector = predict_vector == label_vector
                train_correct += bool_vector.sum()
                n_sample += len(bool_vector)


                if (batch_idx % args.log_interval == 0) and (batch_idx is not 0):
                    print('Batch {} / {}: Batch Loss {:2.4f} Batch Accuracy {:2.4f}'.format(batch_idx,
                                                                                            len(train_loader),
                                                                                            loss.item(),
                                                                                            (train_correct/n_sample)))
                step +=batch_idx

        valid_predict(model, valid_loader, device, train_id_list, train_img_feature_array_list)
        test_predict(model, eval_loader, device, test_id_dict)

    print('Create train_features file...')
    train_pred_dict = {'md5': train_id_list, 'prediction': train_img_feature_array_list}
    pre_submission = pd.DataFrame.from_dict(train_pred_dict)
    feature_cols = ['tcnn_feature' + str(i) for i in range(128)]
    train_prediction_df = pd.DataFrame(pre_submission.prediction.tolist(), columns=feature_cols)
    train_prediction = pd.concat([pre_submission, train_prediction_df], axis=1)
    train_prediction.drop(['prediction'], axis=1, inplace=True)
    train_prediction = reduce_mem_usage(train_prediction)
    train_prediction.to_csv('tcnn_train_features.csv', index=False)
    print('save tcnn_train_features.csv')

    print('Create test_features file...')
    pre_submission = pd.DataFrame(list(test_id_dict.items()), columns=['md', 'prediction'])
    feature_cols = ['tcnn_feature' + str(i) for i in range(128)]
    test_prediction_df = pd.DataFrame(pre_submission.prediction.tolist(), columns=feature_cols)
    test_prediction = pd.concat([pre_submission, test_prediction_df], axis=1)
    test_prediction.drop(['prediction'], axis=1, inplace=True)
    test_prediction = reduce_mem_usage(test_prediction)
    test_prediction.to_csv('tcnn_test_features.csv', index=False)
    print('save tcnn_test_features.csv')

