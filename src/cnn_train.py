import os
import numpy as np
import torch
import torch.nn as nn
import argparse
from tqdm import tqdm
from model.Malware_CNN import MalCNNnet
from utils.dataloader import MalwareTrainDataset, train_val_split
from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
import torch.nn.functional as F
from torch.optim import Adam
from torch.optim import lr_scheduler

def to_np(t):
    return t.cpu().detach().numpy()

def str2bool(v):
    return v.lower() in ("yes", "true", "t", "1")

def save_model(dir_name, model, idx):
    print("MalCNNmodel_{}.model".format(idx))
    save_state_path = os.path.join(dir_name, 'MalCNNmodel_'+ idx +'_dict.pkl')
    torch.save(model.state_dict(), save_state_path)
    print("Chekcpoint saved")

def load_model(dict_name, model, idx):
    save_state_path = os.path.join(dict_name, 'MalCNNmodel_'+ idx +'_dict.pkl')
    state = torch.load(save_state_path)
    model.load_state_dict(state)
    print("Chekcpoint Loaded")

def valid(model,valid_loader,device):
    model.eval()
    total_loss = 0.0
    for batch_idx, (image, tags) in enumerate(valid_loader):
        image = image.to(device)
        tags = tags.to(device)
        outputs = model(image)

        loss_func = nn.CrossEntropyLoss()
        loss = loss_func(outputs, torch.argmax(tags, dim=1))
        total_loss += loss.item()
    logloss = total_loss / len(valid_loader)
    print('Valiadation set Logloss {:2.4f}'.format(logloss))
    return logloss


parser = argparse.ArgumentParser(description='CNN Malware Detection With Pytorch')

train_set = parser.add_mutually_exclusive_group()
parser.add_argument('--dataset', default='train_image', type=str,
                    help='Dataset root directory path')
parser.add_argument('--label_file', default='../train/train.csv', type=str,
                    help='Specify Label Data path')
parser.add_argument('--use_model_weights', default=False, type=str2bool,
                    help='Use Pretrained model')
parser.add_argument('--pretrained_weights', default=None, type=str,
                    help='Pretrained model Idx')
parser.add_argument('--model_save_dir',default='model/weights', type=str,
                    help='Trained Model State Dict Saved Path')
parser.add_argument('--epochs', default=30, type=int,
                    help='Number of epoch for training')
parser.add_argument('--batch_size', default=32, type=int,
                    help='Batch size for training')
# parser.add_argument('--resume', default=None, type=str,
#                     help='Checkpoint state_dict file to resume training from')
# parser.add_argument('--start_iter', default=0, type=int,
#                     help='Resume training at this iter')
parser.add_argument('--num_workers', default=4, type=int,
                    help='Number of workers used in dataloading')
parser.add_argument('--cuda', default=True, type=str2bool,
                    help='Use CUDA to train model')
parser.add_argument('--num_of_class', default=10, type=int,
                    help='Number of classes to predict')
parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,
                    help='initial learning rate')
parser.add_argument('--momentum', default=0.9, type=float,
                    help='Momentum value for optim')
parser.add_argument('--weight_decay', default=5e-4, type=float,
                    help='Weight decay for SGD')
parser.add_argument('--gamma', default=0.8, type=float,
                    help='Gamma update if use SGD as optimizer')
parser.add_argument('--log_interval', default=20, type=int,
                    help='Check model training for each k steps')
# parser.add_argument('--log_dir', default='logs/',
#                     help='Directory for saving tensorboard log')
parser.add_argument('--mode', default='train',
                    help='Choose Train or Eval mode')
parser.add_argument('--do_eval', default=True, type=str2bool,
                    help='Whether to do evaluation on validation set')

args = parser.parse_args()

if torch.cuda.is_available():
    if args.cuda:
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
    if not args.cuda:
        print("WARNING: It looks like you have a CUDA device, but aren't " +
              "using CUDA.\n Run with --cuda for optimal training speed.")
        torch.set_default_tensor_type('torch.FloatTensor')
else:
    torch.set_default_tensor_type('torch.FloatTensor')

# Load Neural Network Model
model = MalCNNnet(num_of_classes= args.num_of_class)

if torch.cuda.is_available() and torch.cuda.device_count() > 0:
    print("GPU device is available")
    device = torch.device('cuda')
    model.to(device)
else:
    device = torch.device('cpu')
    model.to(device)

# Define Loss function
loss_func = nn.CrossEntropyLoss()

if args.cuda:
    model= torch.nn.DataParallel(model)
    model.cuda()
    loss_func.cuda()

# Load pretrained weights
if args.use_model_weights:
    try:
        load_model(args.model_save_dir, model, args.pretrained_weights)
    except FileExistsError:
        print('Please specify the correct pretrained model weights path')

# Define Optimizer
optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
scheduler = lr_scheduler.StepLR(optimizer, 20, gamma=args.gamma)

print('Loading the dataset...')
print('Training MalwareCNN net on: ', args.dataset)
print('Using the specified args:')
print(args)

train_data=MalwareTrainDataset(root_dir=args.dataset,csv_file=args.label_file)
train_indices, val_indices = train_val_split(train_data, validation_split= 0.1, shuffle_dataset= True, random_seed= 42)

train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

train_loader = DataLoader(train_data, batch_size=args.batch_size, num_workers=args.num_workers,sampler=train_sampler)
valid_loader = DataLoader(train_data, batch_size=args.batch_size, num_workers=args.num_workers,sampler=valid_sampler)

# Create model weights save dir if it doesn't exist
if not os.path.exists(args.model_save_dir):
    os.mkdir(args.model_save_dir)

if args.mode == 'train':
    for epoch_idx in tqdm(range(args.epochs)):
        print('Start Epoch {} / {}'.format(epoch_idx, args.epochs))
        train_loss = 0.0
        train_correct = 0.0
        n_sample = 0
        step=0
        model.train()

        for batch_idx, (image, tags) in enumerate(train_loader):
            optimizer.zero_grad()
            image = image.to(device)
            tags = tags.to(device)
            outputs = model(image)
            loss = loss_func(outputs, torch.argmax(tags,dim=1))
            loss.backward()
            optimizer.step()

            predict_vector = np.argmax(to_np(outputs), axis=1)
            label_vector = np.argmax(to_np(tags), axis=1)
            bool_vector = predict_vector == label_vector
            train_correct += bool_vector.sum()
            n_sample += len(bool_vector)



            if batch_idx % args.log_interval == 0:
                print('Batch {} / {}: Batch Loss {:2.4f} Batch Accuracy {:2.4f}'.format(batch_idx,
                                                                                        len(train_loader),
                                                                                        loss.item(),
                                                                                        (train_correct/n_sample)))
            step +=batch_idx

        if args.do_eval:
            valid(model, valid_loader, device)

        scheduler.step()
        save_model(dir_name=args.model_save_dir,model= model, idx='epoch'+str(epoch_idx))
        print('Epoch {} / {}: Loss {:2.4f} '.format(epoch_idx, args.epochs, loss.item()))






